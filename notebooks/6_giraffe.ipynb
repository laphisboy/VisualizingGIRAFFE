{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "611d4f61",
   "metadata": {},
   "source": [
    "1. get camera intrinsic : get_camera_mat()  \n",
    "1. ~ignore getting shape and appearnce code for obj and bg~\n",
    "1. get camera position with camera pose (theta & phi) : to_sphere()    \n",
    "1. get camera coordinate system assuming it points to the center of the sphere : look_at()   \n",
    "1. the carmera coordinate is the rotational matrix and with camera loc, it is camera extrinsic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c1bda4",
   "metadata": {},
   "source": [
    "6. arange 2d array of pixel coordinate and give depth of 1\n",
    "7. mat_mul with intrinsic and then extrinsic gives you p_world (pixels in world) \n",
    "8. mat_mul zeros with intrinsic&extrinsic for camera pos (which we alread obtained)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73eb1d44",
   "metadata": {},
   "source": [
    "9. p_world - camera_origin_world = ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ef7ce45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch # not sure if it will be needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "860188e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = 1\n",
    "v = 0.5\n",
    "depth_range=[0.5, 6.]\n",
    "n_ray_samples=16\n",
    "resolution_vol = 4\n",
    "res = resolution_vol\n",
    "n_points = res * res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "cee30192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camera_mat \n",
      " tensor([[[0.4571, 0.0000, 0.0000, -0.0000],\n",
      "         [0.0000, 0.4571, 0.0000, -0.0000],\n",
      "         [0.0000, 0.0000, 1.0000, -0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 1.0000]]])\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "def get_camera_mat(fov=49.13, invert=True):\n",
    "    # fov = 2 * arctan( sensor / (2 * focal))\n",
    "    # focal = (sensor / 2)  * 1 / (tan(0.5 * fov))\n",
    "    # in our case, sensor = 2 as pixels are in [-1, 1]\n",
    "    focal = 1. / np.tan(0.5 * fov * np.pi/180.)\n",
    "    focal = focal.astype(np.float32)\n",
    "    mat = torch.tensor([\n",
    "        [focal, 0., 0., 0.],\n",
    "        [0., focal, 0., 0.],\n",
    "        [0., 0., 1, 0.],\n",
    "        [0., 0., 0., 1.]\n",
    "    ]).reshape(1, 4, 4)\n",
    "\n",
    "    if invert:\n",
    "        mat = torch.inverse(mat)\n",
    "    return mat\n",
    "\n",
    "camera_mat = get_camera_mat()\n",
    "print(\"camera_mat \\n\", camera_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "4d4b22a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loc \n",
      " [ 1.0000000e+00 -2.4492936e-16  6.1232340e-17]\n"
     ]
    }
   ],
   "source": [
    "# 3 \n",
    "def to_sphere(u, v):\n",
    "    theta = 2 * np.pi * u\n",
    "    phi = np.arccos(1 - 2 * v)\n",
    "    cx = np.sin(phi) * np.cos(theta)\n",
    "    cy = np.sin(phi) * np.sin(theta)\n",
    "    cz = np.cos(phi)\n",
    "    return np.stack([cx, cy, cz], axis=-1)\n",
    "\n",
    "loc = to_sphere(u, v)\n",
    "print(\"loc \\n\", loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "2a218255",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.4492936e-16  1.0000000e+00 -0.0000000e+00]]\n",
      "[[-6.12323400e-17  1.49975978e-32  1.00000000e+00]]\n",
      "[[ 1.0000000e+00 -2.4492936e-16  6.1232340e-17]]\n",
      "world_mat \n",
      " [[[ 2.44929371e-16 -6.12323426e-17  1.00000000e+00  1.00000000e+00]\n",
      "  [ 1.00000000e+00  1.49975976e-32 -2.44929371e-16 -2.44929360e-16]\n",
      "  [-0.00000000e+00  1.00000000e+00  6.12323426e-17  6.12323400e-17]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]]\n"
     ]
    }
   ],
   "source": [
    "# 4\n",
    "def look_at(eye, at=np.array([0, 0, 0]), up=np.array([0, 0, 1]), eps=1e-5,\n",
    "            to_pytorch=True):\n",
    "    at = at.astype(float).reshape(1, 3)\n",
    "    up = up.astype(float).reshape(1, 3)\n",
    "    eye = eye.reshape(-1, 3)\n",
    "    up = up.repeat(eye.shape[0] // up.shape[0], axis=0)\n",
    "    eps = np.array([eps]).reshape(1, 1).repeat(up.shape[0], axis=0)\n",
    "\n",
    "    z_axis = eye - at\n",
    "    z_axis /= np.max(np.stack([np.linalg.norm(z_axis,\n",
    "                                              axis=1, keepdims=True), eps]))\n",
    "\n",
    "    x_axis = np.cross(up, z_axis)\n",
    "    x_axis /= np.max(np.stack([np.linalg.norm(x_axis,\n",
    "                                              axis=1, keepdims=True), eps]))\n",
    "\n",
    "    y_axis = np.cross(z_axis, x_axis)\n",
    "    y_axis /= np.max(np.stack([np.linalg.norm(y_axis,\n",
    "                                              axis=1, keepdims=True), eps]))\n",
    "    \n",
    "    print(x_axis)\n",
    "    print(y_axis)\n",
    "    print(z_axis)\n",
    "    \n",
    "    r_mat = np.concatenate(\n",
    "        (x_axis.reshape(-1, 3, 1), y_axis.reshape(-1, 3, 1), z_axis.reshape(\n",
    "            -1, 3, 1)), axis=2)\n",
    "\n",
    "    if to_pytorch:\n",
    "        r_mat = torch.tensor(r_mat).float()\n",
    "\n",
    "    return r_mat\n",
    "\n",
    "R = look_at(loc)\n",
    "RT = np.eye(4).reshape(1, 4, 4)\n",
    "RT[:, :3, :3] = R\n",
    "RT[:, :3, -1] = loc\n",
    "world_mat = RT\n",
    "print(\"world_mat \\n\", world_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a33cc5d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixels \n",
      " tensor([[[-1.0000,  1.0000],\n",
      "         [-1.0000,  0.3333],\n",
      "         [-1.0000, -0.3333],\n",
      "         [-1.0000, -1.0000],\n",
      "         [-0.3333,  1.0000],\n",
      "         [-0.3333,  0.3333],\n",
      "         [-0.3333, -0.3333],\n",
      "         [-0.3333, -1.0000],\n",
      "         [ 0.3333,  1.0000],\n",
      "         [ 0.3333,  0.3333],\n",
      "         [ 0.3333, -0.3333],\n",
      "         [ 0.3333, -1.0000],\n",
      "         [ 1.0000,  1.0000],\n",
      "         [ 1.0000,  0.3333],\n",
      "         [ 1.0000, -0.3333],\n",
      "         [ 1.0000, -1.0000]]])\n"
     ]
    }
   ],
   "source": [
    "def arange_pixels(resolution=(128, 128), batch_size=1, image_range=(-1., 1.),\n",
    "                  subsample_to=None, invert_y_axis=False):\n",
    "    ''' Arranges pixels for given resolution in range image_range.\n",
    "    The function returns the unscaled pixel locations as integers and the\n",
    "    scaled float values.\n",
    "    Args:\n",
    "        resolution (tuple): image resolution\n",
    "        batch_size (int): batch size\n",
    "        image_range (tuple): range of output points (default [-1, 1])\n",
    "        subsample_to (int): if integer and > 0, the points are randomly\n",
    "            subsampled to this value\n",
    "    '''\n",
    "    h, w = resolution\n",
    "    n_points = resolution[0] * resolution[1]\n",
    "\n",
    "    # Arrange pixel location in scale resolution\n",
    "    pixel_locations = torch.meshgrid(torch.arange(0, w), torch.arange(0, h))\n",
    "    pixel_locations = torch.stack(\n",
    "        [pixel_locations[0], pixel_locations[1]],\n",
    "        dim=-1).long().view(1, -1, 2).repeat(batch_size, 1, 1)\n",
    "    pixel_scaled = pixel_locations.clone().float()\n",
    "\n",
    "    # Shift and scale points to match image_range\n",
    "    scale = (image_range[1] - image_range[0])\n",
    "    loc = scale / 2\n",
    "    pixel_scaled[:, :, 0] = scale * pixel_scaled[:, :, 0] / (w - 1) - loc\n",
    "    pixel_scaled[:, :, 1] = scale * pixel_scaled[:, :, 1] / (h - 1) - loc\n",
    "\n",
    "    # Subsample points if subsample_to is not None and > 0\n",
    "    if (subsample_to is not None and subsample_to > 0 and\n",
    "            subsample_to < n_points):\n",
    "        idx = np.random.choice(pixel_scaled.shape[1], size=(subsample_to,),\n",
    "                               replace=False)\n",
    "        pixel_scaled = pixel_scaled[:, idx]\n",
    "        pixel_locations = pixel_locations[:, idx]\n",
    "\n",
    "    if invert_y_axis:\n",
    "        assert(image_range == (-1, 1))\n",
    "        pixel_scaled[..., -1] *= -1.\n",
    "        pixel_locations[..., -1] = (h - 1) - pixel_locations[..., -1]\n",
    "\n",
    "    return pixel_locations, pixel_scaled\n",
    "\n",
    "pixels = arange_pixels((res, res), 1, invert_y_axis=False)[1]\n",
    "pixels[..., -1] *= -1. # still dunno why this is here\n",
    "print(\"pixels \\n\", pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "aed55708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_pytorch(tensor, return_type=False):\n",
    "    ''' Converts input tensor to pytorch.\n",
    "    Args:\n",
    "        tensor (tensor): Numpy or Pytorch tensor\n",
    "        return_type (bool): whether to return input type\n",
    "    '''\n",
    "    is_numpy = False\n",
    "    if type(tensor) == np.ndarray:\n",
    "        tensor = torch.from_numpy(tensor).float()\n",
    "        is_numpy = True\n",
    "    tensor = tensor.clone()\n",
    "    if return_type:\n",
    "        return tensor, is_numpy\n",
    "    return tensor\n",
    "\n",
    "def transform_to_world(pixels, depth, camera_mat, world_mat, scale_mat=None,\n",
    "                       invert=True, use_absolute_depth=True):\n",
    "    ''' Transforms pixel positions p with given depth value d to world coordinates.\n",
    "    Args:\n",
    "        pixels (tensor): pixel tensor of size B x N x 2\n",
    "        depth (tensor): depth tensor of size B x N x 1\n",
    "        camera_mat (tensor): camera matrix\n",
    "        world_mat (tensor): world matrix\n",
    "        scale_mat (tensor): scale matrix\n",
    "        invert (bool): whether to invert matrices (default: true)\n",
    "    '''\n",
    "    assert(pixels.shape[-1] == 2)\n",
    "\n",
    "    if scale_mat is None:\n",
    "        scale_mat = torch.eye(4).unsqueeze(0).repeat(\n",
    "            camera_mat.shape[0], 1, 1)\n",
    "\n",
    "    # Convert to pytorch\n",
    "    pixels, is_numpy = to_pytorch(pixels, True)\n",
    "    depth = to_pytorch(depth)\n",
    "    camera_mat = to_pytorch(camera_mat)\n",
    "    world_mat = to_pytorch(world_mat)\n",
    "    scale_mat = to_pytorch(scale_mat)\n",
    "\n",
    "    # Invert camera matrices\n",
    "    if invert:\n",
    "        camera_mat = torch.inverse(camera_mat)\n",
    "        world_mat = torch.inverse(world_mat)\n",
    "        scale_mat = torch.inverse(scale_mat)\n",
    "\n",
    "    # Transform pixels to homogen coordinates\n",
    "    pixels = pixels.permute(0, 2, 1)\n",
    "    pixels = torch.cat([pixels, torch.ones_like(pixels)], dim=1)\n",
    "\n",
    "    # Project pixels into camera space\n",
    "    if use_absolute_depth:\n",
    "        pixels[:, :2] = pixels[:, :2] * depth.permute(0, 2, 1).abs()\n",
    "        pixels[:, 2:3] = pixels[:, 2:3] * depth.permute(0, 2, 1)\n",
    "    else:\n",
    "        pixels[:, :3] = pixels[:, :3] * depth.permute(0, 2, 1)\n",
    "        \n",
    "    # Transform pixels to world space\n",
    "    p_world = scale_mat @ world_mat @ camera_mat @ pixels\n",
    "\n",
    "    # Transform p_world back to 3D coordinates\n",
    "    p_world = p_world[:, :3].permute(0, 2, 1)\n",
    "\n",
    "    if is_numpy:\n",
    "        p_world = p_world.numpy()\n",
    "    return p_world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "622a2aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixels_world \n",
      " tensor([[[ 0.0000, -0.4571,  0.4571],\n",
      "         [ 0.0000, -0.4571,  0.1524],\n",
      "         [ 0.0000, -0.4571, -0.1524],\n",
      "         [ 0.0000, -0.4571, -0.4571],\n",
      "         [ 0.0000, -0.1524,  0.4571],\n",
      "         [ 0.0000, -0.1524,  0.1524],\n",
      "         [ 0.0000, -0.1524, -0.1524],\n",
      "         [ 0.0000, -0.1524, -0.4571],\n",
      "         [ 0.0000,  0.1524,  0.4571],\n",
      "         [ 0.0000,  0.1524,  0.1524],\n",
      "         [ 0.0000,  0.1524, -0.1524],\n",
      "         [ 0.0000,  0.1524, -0.4571],\n",
      "         [ 0.0000,  0.4571,  0.4571],\n",
      "         [ 0.0000,  0.4571,  0.1524],\n",
      "         [ 0.0000,  0.4571, -0.1524],\n",
      "         [ 0.0000,  0.4571, -0.4571]]])\n"
     ]
    }
   ],
   "source": [
    "def image_points_to_world(image_points, camera_mat, world_mat, scale_mat=None,\n",
    "                          invert=False, negative_depth=True):\n",
    "    ''' Transforms points on image plane to world coordinates.\n",
    "    In contrast to transform_to_world, no depth value is needed as points on\n",
    "    the image plane have a fixed depth of 1.\n",
    "    Args:\n",
    "        image_points (tensor): image points tensor of size B x N x 2\n",
    "        camera_mat (tensor): camera matrix\n",
    "        world_mat (tensor): world matrix\n",
    "        scale_mat (tensor): scale matrix\n",
    "        invert (bool): whether to invert matrices (default: False)\n",
    "    '''\n",
    "    batch_size, n_pts, dim = image_points.shape\n",
    "    assert(dim == 2)\n",
    "    d_image = torch.ones(batch_size, n_pts, 1)\n",
    "    if negative_depth:\n",
    "        d_image *= -1.\n",
    "    return transform_to_world(image_points, d_image, camera_mat, world_mat,\n",
    "                              scale_mat, invert=invert)\n",
    "\n",
    "pixels_world = image_points_to_world(pixels, camera_mat, world_mat)\n",
    "print(\"pixels_world \\n\", pixels_world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "290463c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camera_world \n",
      " tensor([[[ 1.0000e+00, -2.4493e-16,  6.1232e-17],\n",
      "         [ 1.0000e+00, -2.4493e-16,  6.1232e-17],\n",
      "         [ 1.0000e+00, -2.4493e-16,  6.1232e-17],\n",
      "         [ 1.0000e+00, -2.4493e-16,  6.1232e-17],\n",
      "         [ 1.0000e+00, -2.4493e-16,  6.1232e-17],\n",
      "         [ 1.0000e+00, -2.4493e-16,  6.1232e-17],\n",
      "         [ 1.0000e+00, -2.4493e-16,  6.1232e-17],\n",
      "         [ 1.0000e+00, -2.4493e-16,  6.1232e-17],\n",
      "         [ 1.0000e+00, -2.4493e-16,  6.1232e-17],\n",
      "         [ 1.0000e+00, -2.4493e-16,  6.1232e-17],\n",
      "         [ 1.0000e+00, -2.4493e-16,  6.1232e-17],\n",
      "         [ 1.0000e+00, -2.4493e-16,  6.1232e-17],\n",
      "         [ 1.0000e+00, -2.4493e-16,  6.1232e-17],\n",
      "         [ 1.0000e+00, -2.4493e-16,  6.1232e-17],\n",
      "         [ 1.0000e+00, -2.4493e-16,  6.1232e-17],\n",
      "         [ 1.0000e+00, -2.4493e-16,  6.1232e-17]]])\n"
     ]
    }
   ],
   "source": [
    "def origin_to_world(n_points, camera_mat, world_mat, scale_mat=None,\n",
    "                    invert=False):\n",
    "    ''' Transforms origin (camera location) to world coordinates.\n",
    "    Args:\n",
    "        n_points (int): how often the transformed origin is repeated in the\n",
    "            form (batch_size, n_points, 3)\n",
    "        camera_mat (tensor): camera matrix\n",
    "        world_mat (tensor): world matrix\n",
    "        scale_mat (tensor): scale matrix\n",
    "        invert (bool): whether to invert the matrices (default: false)\n",
    "    '''\n",
    "    \n",
    "    batch_size = camera_mat.shape[0]\n",
    "    device = camera_mat.device\n",
    "    # Create origin in homogen coordinates\n",
    "    p = torch.zeros(batch_size, 4, n_points).to(device)\n",
    "    p[:, -1] = 1.\n",
    "\n",
    "    if scale_mat is None:\n",
    "        scale_mat = torch.eye(4).unsqueeze(\n",
    "            0).repeat(batch_size, 1, 1).to(device)\n",
    "\n",
    "    # Invert matrices\n",
    "    if invert:\n",
    "        camera_mat = torch.inverse(camera_mat)\n",
    "        world_mat = torch.inverse(world_mat)\n",
    "        scale_mat = torch.inverse(scale_mat)\n",
    "        \n",
    "    camera_mat = to_pytorch(camera_mat)\n",
    "    world_mat = to_pytorch(world_mat)\n",
    "    scale_mat = to_pytorch(scale_mat)\n",
    "    \n",
    "    # Apply transformation\n",
    "    p_world = scale_mat @ world_mat @ camera_mat @ p\n",
    "\n",
    "    # Transform points back to 3D coordinates\n",
    "    p_world = p_world[:, :3].permute(0, 2, 1)\n",
    "    return p_world\n",
    "\n",
    "camera_world = origin_to_world(n_points, camera_mat, world_mat)\n",
    "print(\"camera_world \\n\", camera_world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9b741aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ray_vector \n",
      " tensor([[[-1.0000, -0.4571,  0.4571],\n",
      "         [-1.0000, -0.4571,  0.1524],\n",
      "         [-1.0000, -0.4571, -0.1524],\n",
      "         [-1.0000, -0.4571, -0.4571],\n",
      "         [-1.0000, -0.1524,  0.4571],\n",
      "         [-1.0000, -0.1524,  0.1524],\n",
      "         [-1.0000, -0.1524, -0.1524],\n",
      "         [-1.0000, -0.1524, -0.4571],\n",
      "         [-1.0000,  0.1524,  0.4571],\n",
      "         [-1.0000,  0.1524,  0.1524],\n",
      "         [-1.0000,  0.1524, -0.1524],\n",
      "         [-1.0000,  0.1524, -0.4571],\n",
      "         [-1.0000,  0.4571,  0.4571],\n",
      "         [-1.0000,  0.4571,  0.1524],\n",
      "         [-1.0000,  0.4571, -0.1524],\n",
      "         [-1.0000,  0.4571, -0.4571]]])\n"
     ]
    }
   ],
   "source": [
    "ray_vector = pixels_world - camera_world\n",
    "print(\"ray_vector \\n\", ray_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a4521c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "di = depth_range[0] + \\\n",
    "    torch.linspace(0., 1., steps=n_ray_samples).reshape(1, 1, -1) * (\n",
    "        depth_range[1] - depth_range[0])\n",
    "di = di.repeat(batch_size, n_points, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "6b3ce214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5000, 0.8667, 1.2333, 1.6000, 1.9667, 2.3333, 2.7000, 3.0667,\n",
       "          3.4333, 3.8000, 4.1667, 4.5333, 4.9000, 5.2667, 5.6333, 6.0000],\n",
       "         [0.5000, 0.8667, 1.2333, 1.6000, 1.9667, 2.3333, 2.7000, 3.0667,\n",
       "          3.4333, 3.8000, 4.1667, 4.5333, 4.9000, 5.2667, 5.6333, 6.0000],\n",
       "         [0.5000, 0.8667, 1.2333, 1.6000, 1.9667, 2.3333, 2.7000, 3.0667,\n",
       "          3.4333, 3.8000, 4.1667, 4.5333, 4.9000, 5.2667, 5.6333, 6.0000],\n",
       "         [0.5000, 0.8667, 1.2333, 1.6000, 1.9667, 2.3333, 2.7000, 3.0667,\n",
       "          3.4333, 3.8000, 4.1667, 4.5333, 4.9000, 5.2667, 5.6333, 6.0000],\n",
       "         [0.5000, 0.8667, 1.2333, 1.6000, 1.9667, 2.3333, 2.7000, 3.0667,\n",
       "          3.4333, 3.8000, 4.1667, 4.5333, 4.9000, 5.2667, 5.6333, 6.0000],\n",
       "         [0.5000, 0.8667, 1.2333, 1.6000, 1.9667, 2.3333, 2.7000, 3.0667,\n",
       "          3.4333, 3.8000, 4.1667, 4.5333, 4.9000, 5.2667, 5.6333, 6.0000],\n",
       "         [0.5000, 0.8667, 1.2333, 1.6000, 1.9667, 2.3333, 2.7000, 3.0667,\n",
       "          3.4333, 3.8000, 4.1667, 4.5333, 4.9000, 5.2667, 5.6333, 6.0000],\n",
       "         [0.5000, 0.8667, 1.2333, 1.6000, 1.9667, 2.3333, 2.7000, 3.0667,\n",
       "          3.4333, 3.8000, 4.1667, 4.5333, 4.9000, 5.2667, 5.6333, 6.0000],\n",
       "         [0.5000, 0.8667, 1.2333, 1.6000, 1.9667, 2.3333, 2.7000, 3.0667,\n",
       "          3.4333, 3.8000, 4.1667, 4.5333, 4.9000, 5.2667, 5.6333, 6.0000],\n",
       "         [0.5000, 0.8667, 1.2333, 1.6000, 1.9667, 2.3333, 2.7000, 3.0667,\n",
       "          3.4333, 3.8000, 4.1667, 4.5333, 4.9000, 5.2667, 5.6333, 6.0000],\n",
       "         [0.5000, 0.8667, 1.2333, 1.6000, 1.9667, 2.3333, 2.7000, 3.0667,\n",
       "          3.4333, 3.8000, 4.1667, 4.5333, 4.9000, 5.2667, 5.6333, 6.0000],\n",
       "         [0.5000, 0.8667, 1.2333, 1.6000, 1.9667, 2.3333, 2.7000, 3.0667,\n",
       "          3.4333, 3.8000, 4.1667, 4.5333, 4.9000, 5.2667, 5.6333, 6.0000],\n",
       "         [0.5000, 0.8667, 1.2333, 1.6000, 1.9667, 2.3333, 2.7000, 3.0667,\n",
       "          3.4333, 3.8000, 4.1667, 4.5333, 4.9000, 5.2667, 5.6333, 6.0000],\n",
       "         [0.5000, 0.8667, 1.2333, 1.6000, 1.9667, 2.3333, 2.7000, 3.0667,\n",
       "          3.4333, 3.8000, 4.1667, 4.5333, 4.9000, 5.2667, 5.6333, 6.0000],\n",
       "         [0.5000, 0.8667, 1.2333, 1.6000, 1.9667, 2.3333, 2.7000, 3.0667,\n",
       "          3.4333, 3.8000, 4.1667, 4.5333, 4.9000, 5.2667, 5.6333, 6.0000],\n",
       "         [0.5000, 0.8667, 1.2333, 1.6000, 1.9667, 2.3333, 2.7000, 3.0667,\n",
       "          3.4333, 3.8000, 4.1667, 4.5333, 4.9000, 5.2667, 5.6333, 6.0000]]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "7a73a4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.5000, -0.2285,  0.2285],\n",
      "          [ 0.1333, -0.3962,  0.3962],\n",
      "          [-0.2333, -0.5638,  0.5638],\n",
      "          [-0.6000, -0.7314,  0.7314],\n",
      "          [-0.9667, -0.8990,  0.8990],\n",
      "          [-1.3333, -1.0666,  1.0666],\n",
      "          [-1.7000, -1.2342,  1.2342],\n",
      "          [-2.0667, -1.4018,  1.4018],\n",
      "          [-2.4333, -1.5694,  1.5694],\n",
      "          [-2.8000, -1.7370,  1.7370],\n",
      "          [-3.1667, -1.9046,  1.9046],\n",
      "          [-3.5333, -2.0722,  2.0722],\n",
      "          [-3.9000, -2.2398,  2.2398],\n",
      "          [-4.2667, -2.4074,  2.4074],\n",
      "          [-4.6333, -2.5750,  2.5750],\n",
      "          [-5.0000, -2.7426,  2.7426]],\n",
      "\n",
      "         [[ 0.5000, -0.2285,  0.0762],\n",
      "          [ 0.1333, -0.3962,  0.1321],\n",
      "          [-0.2333, -0.5638,  0.1879],\n",
      "          [-0.6000, -0.7314,  0.2438],\n",
      "          [-0.9667, -0.8990,  0.2997],\n",
      "          [-1.3333, -1.0666,  0.3555],\n",
      "          [-1.7000, -1.2342,  0.4114],\n",
      "          [-2.0667, -1.4018,  0.4673],\n",
      "          [-2.4333, -1.5694,  0.5231],\n",
      "          [-2.8000, -1.7370,  0.5790],\n",
      "          [-3.1667, -1.9046,  0.6349],\n",
      "          [-3.5333, -2.0722,  0.6907],\n",
      "          [-3.9000, -2.2398,  0.7466],\n",
      "          [-4.2667, -2.4074,  0.8025],\n",
      "          [-4.6333, -2.5750,  0.8583],\n",
      "          [-5.0000, -2.7426,  0.9142]],\n",
      "\n",
      "         [[ 0.5000, -0.2285, -0.0762],\n",
      "          [ 0.1333, -0.3962, -0.1321],\n",
      "          [-0.2333, -0.5638, -0.1879],\n",
      "          [-0.6000, -0.7314, -0.2438],\n",
      "          [-0.9667, -0.8990, -0.2997],\n",
      "          [-1.3333, -1.0666, -0.3555],\n",
      "          [-1.7000, -1.2342, -0.4114],\n",
      "          [-2.0667, -1.4018, -0.4673],\n",
      "          [-2.4333, -1.5694, -0.5231],\n",
      "          [-2.8000, -1.7370, -0.5790],\n",
      "          [-3.1667, -1.9046, -0.6349],\n",
      "          [-3.5333, -2.0722, -0.6907],\n",
      "          [-3.9000, -2.2398, -0.7466],\n",
      "          [-4.2667, -2.4074, -0.8025],\n",
      "          [-4.6333, -2.5750, -0.8583],\n",
      "          [-5.0000, -2.7426, -0.9142]],\n",
      "\n",
      "         [[ 0.5000, -0.2285, -0.2285],\n",
      "          [ 0.1333, -0.3962, -0.3962],\n",
      "          [-0.2333, -0.5638, -0.5638],\n",
      "          [-0.6000, -0.7314, -0.7314],\n",
      "          [-0.9667, -0.8990, -0.8990],\n",
      "          [-1.3333, -1.0666, -1.0666],\n",
      "          [-1.7000, -1.2342, -1.2342],\n",
      "          [-2.0667, -1.4018, -1.4018],\n",
      "          [-2.4333, -1.5694, -1.5694],\n",
      "          [-2.8000, -1.7370, -1.7370],\n",
      "          [-3.1667, -1.9046, -1.9046],\n",
      "          [-3.5333, -2.0722, -2.0722],\n",
      "          [-3.9000, -2.2398, -2.2398],\n",
      "          [-4.2667, -2.4074, -2.4074],\n",
      "          [-4.6333, -2.5750, -2.5750],\n",
      "          [-5.0000, -2.7426, -2.7426]],\n",
      "\n",
      "         [[ 0.5000, -0.0762,  0.2285],\n",
      "          [ 0.1333, -0.1321,  0.3962],\n",
      "          [-0.2333, -0.1879,  0.5638],\n",
      "          [-0.6000, -0.2438,  0.7314],\n",
      "          [-0.9667, -0.2997,  0.8990],\n",
      "          [-1.3333, -0.3555,  1.0666],\n",
      "          [-1.7000, -0.4114,  1.2342],\n",
      "          [-2.0667, -0.4673,  1.4018],\n",
      "          [-2.4333, -0.5231,  1.5694],\n",
      "          [-2.8000, -0.5790,  1.7370],\n",
      "          [-3.1667, -0.6349,  1.9046],\n",
      "          [-3.5333, -0.6907,  2.0722],\n",
      "          [-3.9000, -0.7466,  2.2398],\n",
      "          [-4.2667, -0.8025,  2.4074],\n",
      "          [-4.6333, -0.8583,  2.5750],\n",
      "          [-5.0000, -0.9142,  2.7426]],\n",
      "\n",
      "         [[ 0.5000, -0.0762,  0.0762],\n",
      "          [ 0.1333, -0.1321,  0.1321],\n",
      "          [-0.2333, -0.1879,  0.1879],\n",
      "          [-0.6000, -0.2438,  0.2438],\n",
      "          [-0.9667, -0.2997,  0.2997],\n",
      "          [-1.3333, -0.3555,  0.3555],\n",
      "          [-1.7000, -0.4114,  0.4114],\n",
      "          [-2.0667, -0.4673,  0.4673],\n",
      "          [-2.4333, -0.5231,  0.5231],\n",
      "          [-2.8000, -0.5790,  0.5790],\n",
      "          [-3.1667, -0.6349,  0.6349],\n",
      "          [-3.5333, -0.6907,  0.6907],\n",
      "          [-3.9000, -0.7466,  0.7466],\n",
      "          [-4.2667, -0.8025,  0.8025],\n",
      "          [-4.6333, -0.8583,  0.8583],\n",
      "          [-5.0000, -0.9142,  0.9142]],\n",
      "\n",
      "         [[ 0.5000, -0.0762, -0.0762],\n",
      "          [ 0.1333, -0.1321, -0.1321],\n",
      "          [-0.2333, -0.1879, -0.1879],\n",
      "          [-0.6000, -0.2438, -0.2438],\n",
      "          [-0.9667, -0.2997, -0.2997],\n",
      "          [-1.3333, -0.3555, -0.3555],\n",
      "          [-1.7000, -0.4114, -0.4114],\n",
      "          [-2.0667, -0.4673, -0.4673],\n",
      "          [-2.4333, -0.5231, -0.5231],\n",
      "          [-2.8000, -0.5790, -0.5790],\n",
      "          [-3.1667, -0.6349, -0.6349],\n",
      "          [-3.5333, -0.6907, -0.6907],\n",
      "          [-3.9000, -0.7466, -0.7466],\n",
      "          [-4.2667, -0.8025, -0.8025],\n",
      "          [-4.6333, -0.8583, -0.8583],\n",
      "          [-5.0000, -0.9142, -0.9142]],\n",
      "\n",
      "         [[ 0.5000, -0.0762, -0.2285],\n",
      "          [ 0.1333, -0.1321, -0.3962],\n",
      "          [-0.2333, -0.1879, -0.5638],\n",
      "          [-0.6000, -0.2438, -0.7314],\n",
      "          [-0.9667, -0.2997, -0.8990],\n",
      "          [-1.3333, -0.3555, -1.0666],\n",
      "          [-1.7000, -0.4114, -1.2342],\n",
      "          [-2.0667, -0.4673, -1.4018],\n",
      "          [-2.4333, -0.5231, -1.5694],\n",
      "          [-2.8000, -0.5790, -1.7370],\n",
      "          [-3.1667, -0.6349, -1.9046],\n",
      "          [-3.5333, -0.6907, -2.0722],\n",
      "          [-3.9000, -0.7466, -2.2398],\n",
      "          [-4.2667, -0.8025, -2.4074],\n",
      "          [-4.6333, -0.8583, -2.5750],\n",
      "          [-5.0000, -0.9142, -2.7426]],\n",
      "\n",
      "         [[ 0.5000,  0.0762,  0.2285],\n",
      "          [ 0.1333,  0.1321,  0.3962],\n",
      "          [-0.2333,  0.1879,  0.5638],\n",
      "          [-0.6000,  0.2438,  0.7314],\n",
      "          [-0.9667,  0.2997,  0.8990],\n",
      "          [-1.3333,  0.3555,  1.0666],\n",
      "          [-1.7000,  0.4114,  1.2342],\n",
      "          [-2.0667,  0.4673,  1.4018],\n",
      "          [-2.4333,  0.5231,  1.5694],\n",
      "          [-2.8000,  0.5790,  1.7370],\n",
      "          [-3.1667,  0.6349,  1.9046],\n",
      "          [-3.5333,  0.6907,  2.0722],\n",
      "          [-3.9000,  0.7466,  2.2398],\n",
      "          [-4.2667,  0.8025,  2.4074],\n",
      "          [-4.6333,  0.8583,  2.5750],\n",
      "          [-5.0000,  0.9142,  2.7426]],\n",
      "\n",
      "         [[ 0.5000,  0.0762,  0.0762],\n",
      "          [ 0.1333,  0.1321,  0.1321],\n",
      "          [-0.2333,  0.1879,  0.1879],\n",
      "          [-0.6000,  0.2438,  0.2438],\n",
      "          [-0.9667,  0.2997,  0.2997],\n",
      "          [-1.3333,  0.3555,  0.3555],\n",
      "          [-1.7000,  0.4114,  0.4114],\n",
      "          [-2.0667,  0.4673,  0.4673],\n",
      "          [-2.4333,  0.5231,  0.5231],\n",
      "          [-2.8000,  0.5790,  0.5790],\n",
      "          [-3.1667,  0.6349,  0.6349],\n",
      "          [-3.5333,  0.6907,  0.6907],\n",
      "          [-3.9000,  0.7466,  0.7466],\n",
      "          [-4.2667,  0.8025,  0.8025],\n",
      "          [-4.6333,  0.8583,  0.8583],\n",
      "          [-5.0000,  0.9142,  0.9142]],\n",
      "\n",
      "         [[ 0.5000,  0.0762, -0.0762],\n",
      "          [ 0.1333,  0.1321, -0.1321],\n",
      "          [-0.2333,  0.1879, -0.1879],\n",
      "          [-0.6000,  0.2438, -0.2438],\n",
      "          [-0.9667,  0.2997, -0.2997],\n",
      "          [-1.3333,  0.3555, -0.3555],\n",
      "          [-1.7000,  0.4114, -0.4114],\n",
      "          [-2.0667,  0.4673, -0.4673],\n",
      "          [-2.4333,  0.5231, -0.5231],\n",
      "          [-2.8000,  0.5790, -0.5790],\n",
      "          [-3.1667,  0.6349, -0.6349],\n",
      "          [-3.5333,  0.6907, -0.6907],\n",
      "          [-3.9000,  0.7466, -0.7466],\n",
      "          [-4.2667,  0.8025, -0.8025],\n",
      "          [-4.6333,  0.8583, -0.8583],\n",
      "          [-5.0000,  0.9142, -0.9142]],\n",
      "\n",
      "         [[ 0.5000,  0.0762, -0.2285],\n",
      "          [ 0.1333,  0.1321, -0.3962],\n",
      "          [-0.2333,  0.1879, -0.5638],\n",
      "          [-0.6000,  0.2438, -0.7314],\n",
      "          [-0.9667,  0.2997, -0.8990],\n",
      "          [-1.3333,  0.3555, -1.0666],\n",
      "          [-1.7000,  0.4114, -1.2342],\n",
      "          [-2.0667,  0.4673, -1.4018],\n",
      "          [-2.4333,  0.5231, -1.5694],\n",
      "          [-2.8000,  0.5790, -1.7370],\n",
      "          [-3.1667,  0.6349, -1.9046],\n",
      "          [-3.5333,  0.6907, -2.0722],\n",
      "          [-3.9000,  0.7466, -2.2398],\n",
      "          [-4.2667,  0.8025, -2.4074],\n",
      "          [-4.6333,  0.8583, -2.5750],\n",
      "          [-5.0000,  0.9142, -2.7426]],\n",
      "\n",
      "         [[ 0.5000,  0.2285,  0.2285],\n",
      "          [ 0.1333,  0.3962,  0.3962],\n",
      "          [-0.2333,  0.5638,  0.5638],\n",
      "          [-0.6000,  0.7314,  0.7314],\n",
      "          [-0.9667,  0.8990,  0.8990],\n",
      "          [-1.3333,  1.0666,  1.0666],\n",
      "          [-1.7000,  1.2342,  1.2342],\n",
      "          [-2.0667,  1.4018,  1.4018],\n",
      "          [-2.4333,  1.5694,  1.5694],\n",
      "          [-2.8000,  1.7370,  1.7370],\n",
      "          [-3.1667,  1.9046,  1.9046],\n",
      "          [-3.5333,  2.0722,  2.0722],\n",
      "          [-3.9000,  2.2398,  2.2398],\n",
      "          [-4.2667,  2.4074,  2.4074],\n",
      "          [-4.6333,  2.5750,  2.5750],\n",
      "          [-5.0000,  2.7426,  2.7426]],\n",
      "\n",
      "         [[ 0.5000,  0.2285,  0.0762],\n",
      "          [ 0.1333,  0.3962,  0.1321],\n",
      "          [-0.2333,  0.5638,  0.1879],\n",
      "          [-0.6000,  0.7314,  0.2438],\n",
      "          [-0.9667,  0.8990,  0.2997],\n",
      "          [-1.3333,  1.0666,  0.3555],\n",
      "          [-1.7000,  1.2342,  0.4114],\n",
      "          [-2.0667,  1.4018,  0.4673],\n",
      "          [-2.4333,  1.5694,  0.5231],\n",
      "          [-2.8000,  1.7370,  0.5790],\n",
      "          [-3.1667,  1.9046,  0.6349],\n",
      "          [-3.5333,  2.0722,  0.6907],\n",
      "          [-3.9000,  2.2398,  0.7466],\n",
      "          [-4.2667,  2.4074,  0.8025],\n",
      "          [-4.6333,  2.5750,  0.8583],\n",
      "          [-5.0000,  2.7426,  0.9142]],\n",
      "\n",
      "         [[ 0.5000,  0.2285, -0.0762],\n",
      "          [ 0.1333,  0.3962, -0.1321],\n",
      "          [-0.2333,  0.5638, -0.1879],\n",
      "          [-0.6000,  0.7314, -0.2438],\n",
      "          [-0.9667,  0.8990, -0.2997],\n",
      "          [-1.3333,  1.0666, -0.3555],\n",
      "          [-1.7000,  1.2342, -0.4114],\n",
      "          [-2.0667,  1.4018, -0.4673],\n",
      "          [-2.4333,  1.5694, -0.5231],\n",
      "          [-2.8000,  1.7370, -0.5790],\n",
      "          [-3.1667,  1.9046, -0.6349],\n",
      "          [-3.5333,  2.0722, -0.6907],\n",
      "          [-3.9000,  2.2398, -0.7466],\n",
      "          [-4.2667,  2.4074, -0.8025],\n",
      "          [-4.6333,  2.5750, -0.8583],\n",
      "          [-5.0000,  2.7426, -0.9142]],\n",
      "\n",
      "         [[ 0.5000,  0.2285, -0.2285],\n",
      "          [ 0.1333,  0.3962, -0.3962],\n",
      "          [-0.2333,  0.5638, -0.5638],\n",
      "          [-0.6000,  0.7314, -0.7314],\n",
      "          [-0.9667,  0.8990, -0.8990],\n",
      "          [-1.3333,  1.0666, -1.0666],\n",
      "          [-1.7000,  1.2342, -1.2342],\n",
      "          [-2.0667,  1.4018, -1.4018],\n",
      "          [-2.4333,  1.5694, -1.5694],\n",
      "          [-2.8000,  1.7370, -1.7370],\n",
      "          [-3.1667,  1.9046, -1.9046],\n",
      "          [-3.5333,  2.0722, -2.0722],\n",
      "          [-3.9000,  2.2398, -2.2398],\n",
      "          [-4.2667,  2.4074, -2.4074],\n",
      "          [-4.6333,  2.5750, -2.5750],\n",
      "          [-5.0000,  2.7426, -2.7426]]]])\n"
     ]
    }
   ],
   "source": [
    "p_i = camera_world.unsqueeze(-2).contiguous() + \\\n",
    "    di.unsqueeze(-1).contiguous() * ray_vector.unsqueeze(-2).contiguous()\n",
    "\n",
    "print(p_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "76d3d464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.0000000e+00, -2.4492936e-16,  6.1232340e-17])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "71dc1632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.44929371e-16,  1.00000000e+00, -0.00000000e+00])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_mat[0, : ,0][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "73f530b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.12323426e-17,  1.49975976e-32,  1.00000000e+00])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_mat[0, : ,1][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e6e564d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.00000000e+00, -2.44929371e-16,  6.12323426e-17])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_mat[0, : ,2][:3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
